{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raaliza Clustering de las imagenes\n",
    "\n",
    "El propósito de este notebook es poder importar los datos extraidos y generar metricas de simulitud sobre lasimagenes en miniatura de los items y poder ver el qué grupos pueden ser comparables entre ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import ssim.ssimlib as pyssim\n",
    "from ssim import ssim as SSIM\n",
    "\n",
    "#from skimage.measure import structural_similarity as ssim\n",
    "from skimage import measure\n",
    "from sklearn.cluster import SpectralClustering, AffinityPropagation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Constant definitions\n",
    "SIM_IMAGE_SIZE = (640, 480)\n",
    "SIFT_RATIO = 0.7\n",
    "MSE_NUMERATOR = 1000.0\n",
    "IMAGES_PER_CLUSTER = 5\n",
    "\n",
    "\"\"\" Returns the normalized similarity value (from 0.0 to 1.0) for the provided pair of images.\n",
    "    The following algorithms are supported:\n",
    "    * SIFT: Scale-invariant Feature Transform\n",
    "    * SSIM: Structural Similarity Index\n",
    "    * CW-SSIM: Complex Wavelet Structural Similarity Index\n",
    "    * MSE: Mean Squared Error\n",
    "\"\"\"\n",
    "def get_image_similarity(img1, img2, algorithm='SIFT'):\n",
    "    # Converting to grayscale and resizing\n",
    "    i1 = cv2.resize(cv2.imread(img1, cv2.IMREAD_GRAYSCALE), SIM_IMAGE_SIZE)\n",
    "    i2 = cv2.resize(cv2.imread(img2, cv2.IMREAD_GRAYSCALE), SIM_IMAGE_SIZE)\n",
    "\n",
    "    similarity = 0.0\n",
    "\n",
    "    if algorithm == 'SIFT':\n",
    "        # Using OpenCV for feature detection and matching\n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        k1, d1 = sift.detectAndCompute(i1, None)\n",
    "        k2, d2 = sift.detectAndCompute(i2, None)\n",
    "\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(d1, d2, k=2)\n",
    "\n",
    "        for m, n in matches:\n",
    "            if m.distance < SIFT_RATIO * n.distance:\n",
    "                similarity += 1.0\n",
    "\n",
    "        # Custom normalization for better variance in the similarity matrix\n",
    "        if similarity == len(matches):\n",
    "            similarity = 1.0\n",
    "        elif similarity > 1.0:\n",
    "            similarity = 1.0 - 1.0/similarity\n",
    "        elif similarity == 1.0:\n",
    "            similarity = 0.1\n",
    "        else:\n",
    "            similarity = 0.0\n",
    "    elif algorithm == 'CW-SSIM':\n",
    "        # FOR EXPERIMENTS ONLY!\n",
    "        # Very slow algorithm - up to 50x times slower than SIFT or SSIM.\n",
    "        # Optimization using CUDA or Cython code should be explored in the future.\n",
    "        #similarity = pyssim.SSIM(img1).cw_ssim_value(img2)\n",
    "        similarity = SSIM(img1).cw_ssim_value(img2)\n",
    "    elif algorithm == 'SSIM':\n",
    "        # Default SSIM implementation of Scikit-Image\n",
    "        similarity = measure.shannon_entropy(i1, i2)\n",
    "    else:\n",
    "        # Using MSE algorithm with custom normalization\n",
    "        err = np.sum((i1.astype(\"float\") - i2.astype(\"float\")) ** 2)\n",
    "        err /= float(i1.shape[0] * i2.shape[1])\n",
    "\n",
    "        if err > 0.0:\n",
    "            similarity = MSE_NUMERATOR / err\n",
    "        else:\n",
    "            similarity = 1.0\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetches all images from the provided directory and calculates the similarity\n",
    "# value per image pair.\n",
    "def build_similarity_matrix(dir_name, algorithm='SIFT'):\n",
    "    images = os.listdir(dir_name)\n",
    "    #num_images = len(images)\n",
    "    num_images=20\n",
    "    sm = np.zeros(shape=(num_images, num_images), dtype=np.float64)\n",
    "    np.fill_diagonal(sm, 1.0)\n",
    "\n",
    "    print(\"Building the similarity matrix using %s algorithm for %d images\" %\n",
    "          (algorithm, num_images))\n",
    "    start_total = datetime.datetime.now()\n",
    "\n",
    "    # Traversing the upper triangle only - transposed matrix will be used\n",
    "    # later for filling the empty cells.\n",
    "    k = 0\n",
    "    for i in range(sm.shape[0]):\n",
    "        for j in range(sm.shape[1]):\n",
    "            j = j + k\n",
    "            if i != j and j < sm.shape[1]:\n",
    "                sm[i][j] = get_image_similarity('%s/%s' % (dir_name, images[i]),\n",
    "                                                '%s/%s' % (dir_name, images[j]),\n",
    "                                                algorithm=algorithm)\n",
    "        k += 1\n",
    "\n",
    "    # Adding the transposed matrix and subtracting the diagonal to obtain\n",
    "    # the symmetric similarity matrix\n",
    "    sm = sm + sm.T - np.diag(sm.diagonal())\n",
    "\n",
    "    end_total = datetime.datetime.now()\n",
    "    print(\"Done - total calculation time: %d seconds\" % (end_total - start_total).total_seconds())\n",
    "    return sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Returns a dictionary with the computed performance metrics of the provided cluster.\n",
    "    Several functions from sklearn.metrics are used to calculate the following:\n",
    "    * Silhouette Coefficient\n",
    "      Values near 1.0 indicate that the sample is far away from the neighboring clusters.\n",
    "      A value of 0.0 indicates that the sample is on or very close to the decision boundary\n",
    "      between two neighboring clusters and negative values indicate that those samples might\n",
    "      have been assigned to the wrong cluster.\n",
    "    * Completeness Score\n",
    "      A clustering result satisfies completeness if all the data points that are members of a\n",
    "      given class are elements of the same cluster. Score between 0.0 and 1.0. 1.0 stands for\n",
    "      perfectly complete labeling.\n",
    "    * Homogeneity Score\n",
    "      A clustering result satisfies homogeneity if all of its clusters contain only data points,\n",
    "      which are members of a single class. 1.0 stands for perfectly homogeneous labeling.\n",
    "\"\"\"\n",
    "def get_cluster_metrics(X, labels, labels_true=None):\n",
    "    metrics_dict = dict()\n",
    "    #X=np.abs(X)\n",
    "    X=np.fill_diagonal(X, X+20)\n",
    "    metrics_dict['Silhouette coefficient'] = metrics.silhouette_score(X,\n",
    "                                                                      labels,\n",
    "                                                                      metric='precomputed')\n",
    "    if labels_true:\n",
    "        metrics_dict['Completeness score'] = metrics.completeness_score(labels_true, labels)\n",
    "        metrics_dict['Homogeneity score'] = metrics.homogeneity_score(labels_true, labels)\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Executes two algorithms for similarity-based clustering:\n",
    "    * Spectral Clustering\n",
    "    * Affinity Propagation\n",
    "    ... and selects the best results according to the clustering performance metrics.\n",
    "\"\"\"\n",
    "def do_cluster(dir_name, algorithm='SIFT', print_metrics=True, labels_true=None):\n",
    "    matrix = build_similarity_matrix(dir_name, algorithm=algorithm)\n",
    "\n",
    "    sc = SpectralClustering(n_clusters=int(matrix.shape[0]/IMAGES_PER_CLUSTER),\n",
    "                            affinity='precomputed').fit(matrix)\n",
    "    sc_metrics = get_cluster_metrics(matrix, sc.labels_, labels_true)\n",
    "\n",
    "    if print_metrics:\n",
    "        print(\"\\nPerformance metrics for Spectral Clustering\")\n",
    "        print(\"Number of clusters: %d\" % len(set(sc.labels_)))\n",
    "        [print(\"%s: %.2f\" % (k, sc_metrics[k])) for k in list(sc_metrics.keys())]\n",
    "\n",
    "    af = AffinityPropagation(affinity='precomputed').fit(matrix)\n",
    "    af_metrics = get_cluster_metrics(matrix, af.labels_, labels_true)\n",
    "\n",
    "    if print_metrics:\n",
    "        print(\"\\nPerformance metrics for Affinity Propagation Clustering\")\n",
    "        print(\"Number of clusters: %d\" % len(set(af.labels_)))\n",
    "        [print(\"%s: %.2f\" % (k, af_metrics[k])) for k in list(af_metrics.keys())]\n",
    "\n",
    "    if (sc_metrics['Silhouette coefficient'] >= af_metrics['Silhouette coefficient']) and \\\n",
    "            (sc_metrics['Completeness score'] >= af_metrics['Completeness score'] or\n",
    "             sc_metrics['Homogeneity score'] >= af_metrics['Homogeneity score']):\n",
    "        print(\"\\nSelected Spectral Clustering for the labeling results\")\n",
    "        return sc.labels_\n",
    "    else:\n",
    "        print(\"\\nSelected Affinity Propagation for the labeling results\")\n",
    "        return af.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "DIR_NAME = '../Images'\n",
    "\n",
    "# Demo for clustering a set of 20 images using 'imgcluster' module.\n",
    "# To be executed in the standalone mode by default. IP[y] Notebook requires some minor adjustments.\n",
    "\n",
    "\"\"\" True (reference) labels for the provided images - defined manually according to the semantic\n",
    "    meaning of images. For example: bear, raccoon and fox should belong to the same cluster.\n",
    "    Please feel free to change the true labels according to your perception of these images  :-)\n",
    "\"\"\"\n",
    "TRUE_LABELS = [1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2]\n",
    "\n",
    "c = do_cluster(DIR_NAME, algorithm='SIFT', print_metrics=True, labels_true=TRUE_LABELS)\n",
    "num_clusters = len(set(c))\n",
    "images = os.listdir(DIR_NAME)\n",
    "plt.axis('off')\n",
    "\n",
    "for n in range(num_clusters):\n",
    "    print(\"\\n --- Images from cluster #%d ---\" % n)\n",
    "\n",
    "    for i in np.argwhere(c == n):\n",
    "        if i != -1:\n",
    "            print(\"Image %s\" % images[i])\n",
    "            img = cv2.imread('%s/%s' % (DIR_NAME, images[i]))\n",
    "            plt.axis('off')\n",
    "            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
